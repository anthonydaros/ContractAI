# ==============================================
# CENTRALIZED CONFIGURATION
# Copy this file to .env in the project root
# ==============================================

# --- Environment ---
ENVIRONMENT=development
NODE_ENV=development

# --- Backend API Settings ---
API_HOST=0.0.0.0
API_PORT=8000
API_DEBUG=true

# CORS (comma-separated origins)
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# File Upload
MAX_UPLOAD_SIZE_MB=10

# --- Ollama / AI Settings ---
# Local development:
OLLAMA_BASE_URL=http://localhost:11434
# Docker (host machine): http://host.docker.internal:11434
# Linux Docker: http://172.17.0.1:11434
# Remote server: https://your-ollama-server.com

OLLAMA_API_KEY=ollama
OLLAMA_MODEL=llama3.1:8b
OLLAMA_EMBEDDING_MODEL=nomic-embed-text
OLLAMA_TEMPERATURE=0.3
OLLAMA_NUM_CTX=4096
OLLAMA_TIMEOUT=120

# --- Frontend Settings ---
# Development:
NEXT_PUBLIC_API_URL=http://localhost:8000
# Production: https://api.your-domain.com

# --- Production URLs (Coolify) ---
# SERVICE_FQDN_BACKEND=api.your-domain.com
# SERVICE_FQDN_FRONTEND=your-domain.com
# SERVICE_URL_BACKEND=https://api.your-domain.com
# SERVICE_URL_FRONTEND=https://your-domain.com
